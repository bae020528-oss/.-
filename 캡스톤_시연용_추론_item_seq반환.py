!pip install ultralytics

# -*- coding: utf-8 -*-
"""ìº¡ìŠ¤í†¤_ì‹œì—°ìš©_ì¶”ë¡ _item_seqë°˜í™˜

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dGmGpn2pZUoiWgvITLv2Up1S7gzLSict
"""

# === Multi-pill Inference: YOLO â†’ ResNet(1324) Top-1 + item_seq ===
# -*- coding: utf-8 -*-
import os
import json
import glob
from pathlib import Path

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models, transforms

from ultralytics import YOLO
from PIL import Image

# -------------------------------------------------
# 0) ê²½ë¡œ / ê¸°ë³¸ ì„¤ì •
# -------------------------------------------------
DRIVE = "/content/drive/MyDrive"

# í…ŒìŠ¤íŠ¸ìš© TS ì´ë¯¸ì§€ (ì›í•˜ëŠ” ê²½ë¡œë¡œ ë°”ê¿”ì„œ ì‚¬ìš©)
IMG_PATH = os.path.join(
    DRIVE,
    "á„á…¢á†¸á„‰á…³á„á…©á†«_á„‹á…¯á†«á„á…¥á†«_á„ƒá…¦á„‹á…µá„á…¥",
    "TS_48_á„ƒá…¡á†«á„‹á…µá†¯.zip",
    "K-018357",
    "K-018357_0_2_0_0_70_000_200.png",
)

BEST_YOLO      = os.path.join(DRIVE, "best.pt")
RESNET_1324_PT = os.path.join(DRIVE, "best_model_generalized.pth")

# 0~999: 1K ë² ì´ìŠ¤ ë¼ë²¨ ë§¤í•‘
CLASS_JSON_1K  = os.path.join(DRIVE, "pill_label_path_sharp_score.json")
# 1000~1323: ì¶”ê°€ 324 í´ë˜ìŠ¤ ë§¤í•‘
CLASS_JSON_324 = os.path.join(DRIVE, "class_mapping_from_cache_1324.json")

# ğŸ”¥ ë°©ê¸ˆ ë§Œë“  ë¹ ë¥¸ K-code â†” item_seq ìºì‹œ
KCODE_ITEMSEQ_CACHE = os.path.join(DRIVE, "kcode_itemseq_cache_fast_1324.json")

for p in [BEST_YOLO, RESNET_1324_PT]:
    assert os.path.exists(p), f"ê°€ì¤‘ì¹˜ íŒŒì¼ ì—†ìŒ: {p}"

assert os.path.exists(KCODE_ITEMSEQ_CACHE), f"item_seq ìºì‹œ ì—†ìŒ: {KCODE_ITEMSEQ_CACHE}"

YOLO_CONF  = 0.25
YOLO_IOU   = 0.45
YOLO_IMGSZ = 640

CROP_SIZE        = 224
MIN_BOX_SIDE_PX  = 40
SQUARE_SCALE     = 1.3

NUM_CLASSES  = 1324
LABEL_OFFSET = 1000        # 0~999: ê¸°ì¡´ 1K, 1000~1323: ì‹ ê·œ 324
MAX_PILLS_MULTI = 4        # ë‹¤ì¤‘ ì•Œì•½ ëª¨ë“œì—ì„œ ìµœëŒ€ ì•Œì•½ ê°œìˆ˜

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", DEVICE)

# -------------------------------------------------
# 1) class_idx â†’ K-code, ê·¸ë¦¬ê³  K-code â†’ item_seq
# -------------------------------------------------
def load_label_map_generic(json_path):
    """
    pill_label_path_sharp_score.json / class_mapping_from_cache_1324.json ì„ ì½ì–´ì„œ
    class_idx â†’ K-code ë§¤í•‘ dictë¥¼ ë§Œë“ ë‹¤.
    (ê°’ì´ íŒŒì¼ëª…ì¸ ê²½ìš° íŒŒì¼ëª…ì—ì„œ ì•ë¶€ë¶„ K-xxxxxx ì¶”ì¶œ)
    """
    if not json_path or not os.path.exists(json_path):
        return {}
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    # class_mapping_from_cache_1324.json êµ¬ì¡° ëŒ€ì‘
    if isinstance(data, dict) and "label_to_kcode" in data:
        data = data["label_to_kcode"]

    out = {}
    if isinstance(data, dict):
        for k, v in data.items():
            try:
                key_int = int(k)
            except:
                continue

            val_str = str(v)
            base = os.path.basename(val_str)
            first = base.split("_")[0]       # "K-012685" ë˜ëŠ” "K012685"

            if first.startswith("K-") and len(first) >= 3:
                kcode = first
            elif first.startswith("K") and len(first) == 7 and first[1:].isdigit():
                kcode = "K-" + first[1:]
            else:
                # ì• ë§¤í•˜ë©´ ê°’ ê·¸ëŒ€ë¡œ (fallback)
                kcode = first

            out[key_int] = kcode

    return out

# 0..999: 1K êµ¬ê°„ìš© K-code ë§¤í•‘
LABEL_MAP_1K  = load_label_map_generic(CLASS_JSON_1K)
# 0..323: ì¶”ê°€ 324 êµ¬ê°„ìš© K-code ë§¤í•‘ (global idxì—ì„œ 1000 ë¹¼ê³  lookup)
LABEL_MAP_324 = load_label_map_generic(CLASS_JSON_324)

def class_idx_to_kcode(global_idx: int):
    """
    ëª¨ë¸ class index â†’ K-code (ì˜ˆ: "K-009272") ë˜ëŠ” None
    """
    if global_idx < LABEL_OFFSET:
        return LABEL_MAP_1K.get(global_idx, None)
    local = global_idx - LABEL_OFFSET
    return LABEL_MAP_324.get(local, None)

# ğŸ”¥ K-code â†” item_seq ìºì‹œ ë¡œë“œ
with open(KCODE_ITEMSEQ_CACHE, "r", encoding="utf-8") as f:
    _item_cache = json.load(f)

KCODE_TO_ITEMSEQ = _item_cache.get("kcode_to_item_seq", {})

def kcode_to_item_seq(kcode: str):
    """
    ìºì‹œì—ì„œ K-code â†’ item_seq ë¬¸ìì—´ì„ ë°”ë¡œ ì¡°íšŒ.
    ì—†ìœ¼ë©´ None.
    """
    if kcode is None:
        return None
    return KCODE_TO_ITEMSEQ.get(kcode)

# -------------------------------------------------
# 2) ResNet 1324 + ì „ì²˜ë¦¬ (ì „ì—­ 1íšŒ ë¡œë“œ)
# -------------------------------------------------
def build_resnet_1324(num_classes=NUM_CLASSES, model_path=RESNET_1324_PT):
    model = models.resnet152(weights=None)
    in_f = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Dropout(p=0.5),
        nn.Linear(in_f, num_classes)
    )

    state = torch.load(model_path, map_location="cpu")
    if isinstance(state, dict):
        if "model_state_dict" in state:
            state = state["model_state_dict"]
        elif "model" in state:
            state = state["model"]
    missing, unexpected = model.load_state_dict(state, strict=False)
    if missing or unexpected:
        print(f"â„¹ï¸ state_dict load: missing={len(missing)}, unexpected={len(unexpected)}")

    model.to(DEVICE)
    model.eval()

    if DEVICE.type == "cuda":
        model.half()

    return model

RESNET_MODEL = build_resnet_1324()

base_transform = transforms.Compose([
    transforms.Resize((CROP_SIZE, CROP_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
])

def preprocess_pil(pil_img):
    t = base_transform(pil_img)
    if DEVICE.type == "cuda":
        return t.half()
    return t

@torch.no_grad()
def predict_resnet_batch_top1(pil_imgs):
    """
    pil_imgs: [PIL.Image, ...]
    return: [{"idx": int, "prob": float}, ...]  (ê° crop ë‹¹ Top-1ë§Œ)
    """
    if not pil_imgs:
        return []
    xs = [preprocess_pil(im) for im in pil_imgs]
    x = torch.stack(xs).to(DEVICE)

    logits = RESNET_MODEL(x)
    probs = F.softmax(logits, dim=1)
    top1_prob, top1_idx = torch.topk(probs, 1, dim=1)

    all_results = []
    for i in range(probs.shape[0]):
        all_results.append({
            "idx": int(top1_idx[i, 0].item()),
            "prob": float(top1_prob[i, 0].item()),
        })
    return all_results

# -------------------------------------------------
# 3) YOLO ê°ì§€ + í¬ë¡­ (ë‹¤ì¤‘ ì•Œì•½ ëª¨ë“œ)
# -------------------------------------------------
YOLO_DEVICE = 0 if DEVICE.type == "cuda" else "cpu"
YOLO_MODEL = YOLO(BEST_YOLO)

def detect_yolo_boxes(img_path):
    """
    YOLOë¡œ ì•Œì•½ bbox ê²€ì¶œ.
    return:
      img (PIL.Image),
      boxes: [[x1,y1,x2,y2], ...],
      confs: [conf, ...]
    """
    det = YOLO_MODEL(
        img_path,
        imgsz=YOLO_IMGSZ,
        conf=YOLO_CONF,
        iou=YOLO_IOU,
        device=YOLO_DEVICE,
        verbose=False
    )[0]

    img = Image.open(img_path).convert("RGB")
    W, H = img.size

    boxes = []
    confs = []
    if det.boxes is not None and len(det.boxes) > 0:
        xyxy = det.boxes.xyxy.cpu().numpy().tolist()
        conf = det.boxes.conf.cpu().numpy().tolist()
        for (b, c) in zip(xyxy, conf):
            x1, y1, x2, y2 = map(int, b)
            x1 = max(0, x1)
            y1 = max(0, y1)
            x2 = min(W-1, x2)
            y2 = min(H-1, y2)
            if (x2-x1) >= MIN_BOX_SIDE_PX and (y2-y1) >= MIN_BOX_SIDE_PX:
                boxes.append([x1, y1, x2, y2])
                confs.append(float(c))

    return img, boxes, confs

def square_crop_from_bbox(pil_img, xyxy, scale=1.3):
    """
    bbox ê¸°ì¤€ìœ¼ë¡œ ì •ì‚¬ê°í˜• soft crop ìƒì„±.
    """
    W, H = pil_img.size
    x1, y1, x2, y2 = xyxy
    cx = (x1 + x2) / 2.0
    cy = (y1 + y2) / 2.0
    bw = x2 - x1
    bh = y2 - y1
    side = max(bw, bh) * scale
    side = max(side, MIN_BOX_SIDE_PX * 1.5)

    half = side / 2.0
    nx1 = int(round(cx - half))
    ny1 = int(round(cy - half))
    nx2 = int(round(cx + half))
    ny2 = int(round(cy + half))

    nx1 = max(0, nx1)
    ny1 = max(0, ny1)
    nx2 = min(W, nx2)
    ny2 = min(H, ny2)
    if nx2 <= nx1 or ny2 <= ny1:
        return None

    return pil_img.crop((nx1, ny1, nx2, ny2))

# -------------------------------------------------
# 4) ë‹¤ì¤‘ ì•Œì•½ Top-1 + item_seq ì¶”ë¡  API
# -------------------------------------------------
def infer_pill_image_multi_top1(img_path: str,
                                max_pills: int = MAX_PILLS_MULTI):
    """
    ì´ë¯¸ì§€ ì•ˆì— ìµœëŒ€ max_pillsê°œì˜ ì•Œì•½ì´ ìˆë‹¤ê³  ê°€ì •í•˜ê³ ,
    ê° ì•Œì•½ bboxì— ëŒ€í•´ ResNet(1324) Top-1 + item_seqë¥¼ ì¶”ë¡ .

    return í˜•ì‹:
      [
        {
          "pill_index": 0,                 # ëª‡ ë²ˆì§¸ ì•Œì•½ì¸ì§€ (0ë¶€í„°)
          "bbox": [x1,y1,x2,y2] or None,   # YOLO bbox
          "class_idx": <int>,              # ResNet class index
          "kcode": "<K-xxxxxx>" or None,   # K-code (ì—†ìœ¼ë©´ None)
          "item_seq": "<item_seq>" or None,# ìºì‹œì—ì„œ ì°¾ì€ item_seq (ì—†ìœ¼ë©´ None)
          "prob": <float>,                 # Top-1 í™•ë¥ 
        },
        ...
      ]
    """
    assert os.path.exists(img_path), f"ì´ë¯¸ì§€ ì—†ìŒ: {img_path}"

    img, boxes, confs = detect_yolo_boxes(img_path)
    results = []

    # YOLOê°€ ì•„ë¬´ê²ƒë„ ëª» ì¡ìœ¼ë©´, ì „ì²´ ì´ë¯¸ì§€ë¥¼ ì•Œì•½ í•˜ë‚˜ë¡œ ê°„ì£¼
    if not boxes:
        crops = [img.copy()]
        preds = predict_resnet_batch_top1(crops)
        if preds:
            p = preds[0]
            idx = p["idx"]
            prob = p["prob"]
            kcode = class_idx_to_kcode(idx)
            item_seq = kcode_to_item_seq(kcode)
            results.append({
                "pill_index": 0,
                "bbox": None,
                "class_idx": idx,
                "kcode": kcode,
                "item_seq": item_seq,
                "prob": prob,
            })
        return results

    # YOLO confidence ê¸°ì¤€ ìƒìœ„ max_pillsê°œ bboxë§Œ ì‚¬ìš©
    idx_sorted = sorted(range(len(boxes)), key=lambda i: confs[i], reverse=True)
    idx_keep   = idx_sorted[:max_pills]

    crops = []
    kept_boxes = []
    for i in idx_keep:
        bbox = boxes[i]
        sq = square_crop_from_bbox(img, bbox, scale=SQUARE_SCALE)
        if sq is None:
            continue
        crops.append(sq)
        kept_boxes.append(bbox)

    # í˜¹ì‹œ cropì´ í•˜ë‚˜ë„ ì•ˆ ë§Œë“¤ì–´ì¡Œìœ¼ë©´ ì „ì²´ ì´ë¯¸ì§€ 1ê°œë¡œ fallback
    if not crops:
        crops = [img.copy()]
        kept_boxes = [None]

    preds = predict_resnet_batch_top1(crops)

    for pill_idx, (bbox, p) in enumerate(zip(kept_boxes, preds)):
        idx = p["idx"]
        prob = p["prob"]
        kcode = class_idx_to_kcode(idx)
        item_seq = kcode_to_item_seq(kcode)
        results.append({
            "pill_index": pill_idx,
            "bbox": bbox,
            "class_idx": idx,
            "kcode": kcode,
            "item_seq": item_seq,
            "prob": prob,
        })

    return results

# -------------------------------------------------
# 5) ì§ì ‘ ì‹¤í–‰ ì˜ˆì‹œ
# -------------------------------------------------
if __name__ == "__main__":
    res_list = infer_pill_image_multi_top1(IMG_PATH, max_pills=4)

    print("=== MULTI-PILL TOP-1 + item_seq RESULTS ===")
    if not res_list:
        print("No pills detected / predicted.")
    else:
        for r in res_list:
            print(
                f"[Pill #{r['pill_index']}] bbox={r['bbox']} "
                f"class_idx={r['class_idx']}, kcode={r['kcode']}, "
                f"item_seq={r['item_seq']}, prob={r['prob']*100:.2f}%"
            )

    # ë‹¤ë¥¸ APIì— ë„˜ê¸¸ ë• res_list ê·¸ëŒ€ë¡œ json.dumps í•´ì„œ ì‚¬ìš©í•˜ë©´ ë¨
    # import json
    # print(json.dumps(res_list, ensure_ascii=False, indent=2))
