{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNL8Jp5dnCFT",
        "outputId": "a573c9ec-22c6-4aab-b531-32ef9e708954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "=== MULTI MODE (up to 4 pills) TOP-1 RESULTS ===\n",
            "[Pill #0] bbox=None class_idx=1054, dl_idx=18356, prob=99.71%\n"
          ]
        }
      ],
      "source": [
        "# === Fast Inference API (Multi-pill, Top-1 Only) ===\n",
        "# YOLO → 최대 4개 알약 bbox 탐지 → 각 알약별 ResNet(1324) Top-1 (dl_idx 계산식)\n",
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models, transforms\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 0) 경로 / 기본 설정\n",
        "# -------------------------------------------------\n",
        "DRIVE = \"/content/drive/MyDrive\"\n",
        "\n",
        "IMG_PATH = \"/content/drive/MyDrive/캡스톤_원천_데이터/TS_48_단일.zip/K-018357/K-018357_0_2_0_0_70_000_200.png\"\n",
        "\n",
        "BEST_YOLO      = os.path.join(DRIVE, \"best.pt\")\n",
        "RESNET_1324_PT = os.path.join(DRIVE, \"best_model_generalized.pth\")\n",
        "CLASS_JSON_1K  = os.path.join(DRIVE, \"pill_label_path_sharp_score.json\")\n",
        "CLASS_JSON_324 = os.path.join(DRIVE, \"class_mapping_from_cache_1324.json\")\n",
        "\n",
        "for p in [BEST_YOLO, RESNET_1324_PT]:\n",
        "    assert os.path.exists(p), f\"가중치 파일 없음: {p}\"\n",
        "\n",
        "YOLO_CONF  = 0.25\n",
        "YOLO_IOU   = 0.45\n",
        "YOLO_IMGSZ = 640\n",
        "\n",
        "CROP_SIZE        = 224\n",
        "MIN_BOX_SIDE_PX  = 40\n",
        "SQUARE_SCALE     = 1.3\n",
        "\n",
        "NUM_CLASSES  = 1324\n",
        "LABEL_OFFSET = 1000\n",
        "\n",
        "MAX_PILLS_MULTI = 4\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 1) 라벨 맵 + dl_idx 계산\n",
        "# -------------------------------------------------\n",
        "def load_label_map_generic(json_path):\n",
        "    if not json_path or not os.path.exists(json_path):\n",
        "        return {}\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    if isinstance(data, dict) and \"label_to_kcode\" in data:\n",
        "        data = data[\"label_to_kcode\"]\n",
        "\n",
        "    out = {}\n",
        "    if isinstance(data, dict):\n",
        "        for k, v in data.items():\n",
        "            try:\n",
        "                key_int = int(k)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            val_str = str(v)\n",
        "            base = os.path.basename(val_str)\n",
        "            first = base.split(\"_\")[0]\n",
        "\n",
        "            if first.startswith(\"K-\") and len(first) == 8 and first[2:].isdigit():\n",
        "                kcode = first\n",
        "            elif first.startswith(\"K\") and len(first) == 7 and first[1:].isdigit():\n",
        "                kcode = \"K-\" + first[1:]\n",
        "            else:\n",
        "                kcode = first\n",
        "\n",
        "            out[key_int] = kcode\n",
        "\n",
        "    return out\n",
        "\n",
        "LABEL_MAP_1K  = load_label_map_generic(CLASS_JSON_1K)\n",
        "LABEL_MAP_324 = load_label_map_generic(CLASS_JSON_324)\n",
        "\n",
        "def class_idx_to_kcode(global_idx: int) -> str:\n",
        "    if global_idx < LABEL_OFFSET:\n",
        "        return LABEL_MAP_1K.get(global_idx, f\"imagenet_{global_idx}\")\n",
        "    local = global_idx - LABEL_OFFSET\n",
        "    return LABEL_MAP_324.get(local, f\"unknown_{local}\")\n",
        "\n",
        "def kcode_to_dl_idx(kcode: str) -> str:\n",
        "    if len(kcode) >= 7:\n",
        "        tail = kcode[-6:]\n",
        "        if tail.isdigit():\n",
        "            val = int(tail)\n",
        "            dl_val = val - 1\n",
        "            if dl_val >= 0:\n",
        "                return str(dl_val)\n",
        "    return kcode\n",
        "\n",
        "def idx_to_dl_idx(global_idx: int) -> str:\n",
        "    kcode = class_idx_to_kcode(global_idx)\n",
        "    return kcode_to_dl_idx(kcode)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 2) ResNet 1324 + 전처리 (전역 1회)\n",
        "# -------------------------------------------------\n",
        "def build_resnet_1324(num_classes=NUM_CLASSES, model_path=RESNET_1324_PT):\n",
        "    model = models.resnet152(weights=None)\n",
        "    in_f = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(in_f, num_classes)\n",
        "    )\n",
        "\n",
        "    state = torch.load(model_path, map_location=\"cpu\")\n",
        "    if isinstance(state, dict):\n",
        "        if \"model_state_dict\" in state:\n",
        "            state = state[\"model_state_dict\"]\n",
        "        elif \"model\" in state:\n",
        "            state = state[\"model\"]\n",
        "    missing, unexpected = model.load_state_dict(state, strict=False)\n",
        "    if missing or unexpected:\n",
        "        print(f\"ℹ️ state_dict load: missing={len(missing)}, unexpected={len(unexpected)}\")\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    if DEVICE.type == \"cuda\":\n",
        "        model.half()\n",
        "\n",
        "    return model\n",
        "\n",
        "RESNET_MODEL = build_resnet_1324()\n",
        "\n",
        "base_transform = transforms.Compose([\n",
        "    transforms.Resize((CROP_SIZE, CROP_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "def preprocess_pil(pil_img):\n",
        "    t = base_transform(pil_img)\n",
        "    if DEVICE.type == \"cuda\":\n",
        "        return t.half()\n",
        "    return t\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_resnet_batch_top1(pil_imgs):\n",
        "    if not pil_imgs:\n",
        "        return []\n",
        "    xs = [preprocess_pil(im) for im in pil_imgs]\n",
        "    x = torch.stack(xs).to(DEVICE)\n",
        "\n",
        "    if DEVICE.type == 'cuda':\n",
        "        logits = RESNET_MODEL(x)\n",
        "    else:\n",
        "        logits = RESNET_MODEL(x)\n",
        "\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "    top1_prob, top1_idx = torch.topk(probs, 1, dim=1)\n",
        "\n",
        "    all_results = []\n",
        "    for i in range(probs.shape[0]):\n",
        "        all_results.append({\n",
        "            \"idx\": int(top1_idx[i, 0].item()),\n",
        "            \"prob\": float(top1_prob[i, 0].item()),\n",
        "        })\n",
        "    return all_results\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 3) YOLO 감지 + 크롭\n",
        "# -------------------------------------------------\n",
        "YOLO_DEVICE = 0 if DEVICE.type == \"cuda\" else \"cpu\"\n",
        "YOLO_MODEL = YOLO(BEST_YOLO)\n",
        "\n",
        "def detect_yolo_boxes(img_path):\n",
        "    det = YOLO_MODEL(\n",
        "        img_path,\n",
        "        imgsz=YOLO_IMGSZ,\n",
        "        conf=YOLO_CONF,\n",
        "        iou=YOLO_IOU,\n",
        "        device=YOLO_DEVICE,\n",
        "        verbose=False\n",
        "    )[0]\n",
        "\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    W, H = img.size\n",
        "\n",
        "    boxes = []\n",
        "    confs = []\n",
        "    if det.boxes is not None and len(det.boxes) > 0:\n",
        "        xyxy = det.boxes.xyxy.cpu().numpy().tolist()\n",
        "        conf = det.boxes.conf.cpu().numpy().tolist()\n",
        "        for (b, c) in zip(xyxy, conf):\n",
        "            x1, y1, x2, y2 = map(int, b)\n",
        "            x1 = max(0, x1)\n",
        "            y1 = max(0, y1)\n",
        "            x2 = min(W-1, x2)\n",
        "            y2 = min(H-1, y2)\n",
        "            if (x2-x1) >= MIN_BOX_SIDE_PX and (y2-y1) >= MIN_BOX_SIDE_PX:\n",
        "                boxes.append([x1, y1, x2, y2])\n",
        "                confs.append(float(c))\n",
        "\n",
        "    return img, boxes, confs\n",
        "\n",
        "def square_crop_from_bbox(pil_img, xyxy, scale=1.3):\n",
        "    W, H = pil_img.size\n",
        "    x1, y1, x2, y2 = xyxy\n",
        "    cx = (x1 + x2) / 2.0\n",
        "    cy = (y1 + y2) / 2.0\n",
        "    bw = x2 - x1\n",
        "    bh = y2 - y1\n",
        "    side = max(bw, bh) * scale\n",
        "    side = max(side, MIN_BOX_SIDE_PX * 1.5)\n",
        "\n",
        "    half = side / 2.0\n",
        "    nx1 = int(round(cx - half))\n",
        "    ny1 = int(round(cy - half))\n",
        "    nx2 = int(round(cx + half))\n",
        "    ny2 = int(round(cy + half))\n",
        "\n",
        "    nx1 = max(0, nx1)\n",
        "    ny1 = max(0, ny1)\n",
        "    nx2 = min(W, nx2)\n",
        "    ny2 = min(H, ny2)\n",
        "    if nx2 <= nx1 or ny2 <= ny1:\n",
        "        return None\n",
        "\n",
        "    return pil_img.crop((nx1, ny1, nx2, ny2))\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 4) 다중 알약 Top-1 추론\n",
        "# -------------------------------------------------\n",
        "def infer_pill_image_multi_top1(img_path: str,\n",
        "                                max_pills: int = MAX_PILLS_MULTI):\n",
        "    \"\"\"\n",
        "    최대 max_pills개의 알약에 대해 각 알약별 Top-1만 반환.\n",
        "    return:\n",
        "      [\n",
        "        {\n",
        "          \"pill_index\": 0,\n",
        "          \"bbox\": [x1,y1,x2,y2] or None,\n",
        "          \"idx\": <class_idx>,\n",
        "          \"dl_idx\": \"<dl_idx>\",\n",
        "          \"prob\": <float>,\n",
        "        },\n",
        "        ...\n",
        "      ]\n",
        "    \"\"\"\n",
        "    img, boxes, confs = detect_yolo_boxes(img_path)\n",
        "    results = []\n",
        "\n",
        "    # YOLO가 아무것도 못 잡았으면 전체 이미지를 pill 0으로 취급\n",
        "    if not boxes:\n",
        "        crops = [img.copy()]\n",
        "        preds = predict_resnet_batch_top1(crops)\n",
        "        if preds:\n",
        "            p = preds[0]\n",
        "            dl_idx = idx_to_dl_idx(p[\"idx\"])\n",
        "            results.append({\n",
        "                \"pill_index\": 0,\n",
        "                \"bbox\": None,\n",
        "                \"idx\": p[\"idx\"],\n",
        "                \"dl_idx\": dl_idx,\n",
        "                \"prob\": p[\"prob\"],\n",
        "            })\n",
        "        return results\n",
        "\n",
        "    # conf 기준 상위 max_pills 선택\n",
        "    idx_sorted = sorted(range(len(boxes)), key=lambda i: confs[i], reverse=True)\n",
        "    idx_keep   = idx_sorted[:max_pills]\n",
        "\n",
        "    crops = []\n",
        "    kept_boxes = []\n",
        "    for i in idx_keep:\n",
        "        bbox = boxes[i]\n",
        "        sq = square_crop_from_bbox(img, bbox, scale=SQUARE_SCALE)\n",
        "        if sq is None:\n",
        "            continue\n",
        "        crops.append(sq)\n",
        "        kept_boxes.append(bbox)\n",
        "\n",
        "    if not crops:\n",
        "        crops = [img.copy()]\n",
        "        kept_boxes = [None]\n",
        "\n",
        "    preds = predict_resnet_batch_top1(crops)\n",
        "\n",
        "    for pill_idx, (bbox, p) in enumerate(zip(kept_boxes, preds)):\n",
        "        dl_idx = idx_to_dl_idx(p[\"idx\"])\n",
        "        results.append({\n",
        "            \"pill_index\": pill_idx,\n",
        "            \"bbox\": bbox,\n",
        "            \"idx\": p[\"idx\"],\n",
        "            \"dl_idx\": dl_idx,\n",
        "            \"prob\": p[\"prob\"],\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 5) 테스트 실행\n",
        "# -------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    assert os.path.exists(IMG_PATH), f\"이미지 없음: {IMG_PATH}\"\n",
        "\n",
        "    print(\"=== MULTI MODE (up to 4 pills) TOP-1 RESULTS ===\")\n",
        "    out = infer_pill_image_multi_top1(IMG_PATH, max_pills=4)\n",
        "    for r in out:\n",
        "        print(\n",
        "            f\"[Pill #{r['pill_index']}] bbox={r['bbox']} \"\n",
        "            f\"class_idx={r['idx']}, dl_idx={r['dl_idx']}, prob={r['prob']*100:.2f}%\"\n",
        "        )\n",
        "    # 다른 API에 넘길 땐 out 그대로 json.dumps 해서 쓰면 됨\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBN11CGInLIl",
        "outputId": "ef2b9199-828a-40b9-b492-a2b8bbcf92fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "V_ihNNtjnOdn",
        "outputId": "25138fc2-3593-43b1-cf25-4de631524420"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.228-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.228-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.228 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    }
  ]
}