{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipibphMTYo2T",
        "outputId": "b27a2192-c53b-4579-fbbb-62acdc0fcf07"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.228-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.228-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.228 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojr4YRgSN-uv",
        "outputId": "900d5528-d0b6-464e-d2f3-83c7aefdbb95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "=== SINGLE MODE TOP-1 RESULT ===\n",
            "class_idx=1262, dl_idx=9271, prob=99.13%\n"
          ]
        }
      ],
      "source": [
        "# === Fast Inference API (Single-pill, Top-1 Only) ===\n",
        "# YOLO → (조건부 전체이미지 / 소프트 크롭)\n",
        "#     → ResNet(1324) 최종 Top-1 (dl_idx 계산식 기반)\n",
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models, transforms\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 0) 경로 / 기본 설정\n",
        "# -------------------------------------------------\n",
        "DRIVE = \"/content/drive/MyDrive\"\n",
        "\n",
        "# 테스트용 기본 이미지 경로 (필요하면 이 값만 바꿔서 사용)\n",
        "IMG_PATH = \"/content/drive/MyDrive/캡스톤_원천_데이터/TS_34_단일.zip/K-009272/K-009272_0_1_0_0_70_000_200.png\"\n",
        "\n",
        "BEST_YOLO      = os.path.join(DRIVE, \"best.pt\")\n",
        "RESNET_1324_PT = os.path.join(DRIVE, \"best_model_generalized.pth\")\n",
        "CLASS_JSON_1K  = os.path.join(DRIVE, \"pill_label_path_sharp_score.json\")\n",
        "CLASS_JSON_324 = os.path.join(DRIVE, \"class_mapping_from_cache_1324.json\")\n",
        "\n",
        "for p in [BEST_YOLO, RESNET_1324_PT]:\n",
        "    assert os.path.exists(p), f\"가중치 파일 없음: {p}\"\n",
        "\n",
        "YOLO_CONF  = 0.25\n",
        "YOLO_IOU   = 0.45\n",
        "YOLO_IMGSZ = 640\n",
        "\n",
        "CROP_SIZE        = 224\n",
        "MIN_BOX_SIDE_PX  = 40\n",
        "FULL_IMAGE_AREA_RATIO_THRESHOLD = 0.65\n",
        "SQUARE_SCALE     = 1.3\n",
        "\n",
        "NUM_CLASSES  = 1324\n",
        "LABEL_OFFSET = 1000\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 1) 라벨 맵 로드 (class_idx → K-코드, dl_idx 계산)\n",
        "# -------------------------------------------------\n",
        "def load_label_map_generic(json_path):\n",
        "    if not json_path or not os.path.exists(json_path):\n",
        "        return {}\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    if isinstance(data, dict) and \"label_to_kcode\" in data:\n",
        "        data = data[\"label_to_kcode\"]\n",
        "\n",
        "    out = {}\n",
        "    if isinstance(data, dict):\n",
        "        for k, v in data.items():\n",
        "            try:\n",
        "                key_int = int(k)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            val_str = str(v)\n",
        "            base = os.path.basename(val_str)\n",
        "            first = base.split(\"_\")[0]   # \"K013101\" or \"K-009272\" ...\n",
        "\n",
        "            if first.startswith(\"K-\") and len(first) == 8 and first[2:].isdigit():\n",
        "                kcode = first\n",
        "            elif first.startswith(\"K\") and len(first) == 7 and first[1:].isdigit():\n",
        "                kcode = \"K-\" + first[1:]\n",
        "            else:\n",
        "                kcode = first\n",
        "\n",
        "            out[key_int] = kcode\n",
        "\n",
        "    return out\n",
        "\n",
        "LABEL_MAP_1K  = load_label_map_generic(CLASS_JSON_1K)   # 0..999\n",
        "LABEL_MAP_324 = load_label_map_generic(CLASS_JSON_324)  # 0..323 (for 1000~1323)\n",
        "\n",
        "def class_idx_to_kcode(global_idx: int) -> str:\n",
        "    if global_idx < LABEL_OFFSET:\n",
        "        return LABEL_MAP_1K.get(global_idx, f\"imagenet_{global_idx}\")\n",
        "    local = global_idx - LABEL_OFFSET\n",
        "    return LABEL_MAP_324.get(local, f\"unknown_{local}\")\n",
        "\n",
        "def kcode_to_dl_idx(kcode: str) -> str:\n",
        "    # \"K-009272\" → \"9271\"\n",
        "    if len(kcode) >= 7:\n",
        "        tail = kcode[-6:]\n",
        "        if tail.isdigit():\n",
        "            val = int(tail)\n",
        "            dl_val = val - 1\n",
        "            if dl_val >= 0:\n",
        "                return str(dl_val)\n",
        "    return kcode  # fallback\n",
        "\n",
        "def idx_to_dl_idx(global_idx: int) -> str:\n",
        "    kcode = class_idx_to_kcode(global_idx)\n",
        "    return kcode_to_dl_idx(kcode)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 2) ResNet 1324 모델 + 전처리 (전역 1회 로드)\n",
        "# -------------------------------------------------\n",
        "def build_resnet_1324(num_classes=NUM_CLASSES, model_path=RESNET_1324_PT):\n",
        "    model = models.resnet152(weights=None)\n",
        "    in_f = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(in_f, num_classes)\n",
        "    )\n",
        "\n",
        "    state = torch.load(model_path, map_location=\"cpu\")\n",
        "    if isinstance(state, dict):\n",
        "        if \"model_state_dict\" in state:\n",
        "            state = state[\"model_state_dict\"]\n",
        "        elif \"model\" in state:\n",
        "            state = state[\"model\"]\n",
        "    missing, unexpected = model.load_state_dict(state, strict=False)\n",
        "    if missing or unexpected:\n",
        "        print(f\"ℹ️ state_dict load: missing={len(missing)}, unexpected={len(unexpected)}\")\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    if DEVICE.type == \"cuda\":\n",
        "        model.half()\n",
        "\n",
        "    return model\n",
        "\n",
        "RESNET_MODEL = build_resnet_1324()\n",
        "\n",
        "base_transform = transforms.Compose([\n",
        "    transforms.Resize((CROP_SIZE, CROP_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "def preprocess_pil(pil_img):\n",
        "    t = base_transform(pil_img)\n",
        "    if DEVICE.type == \"cuda\":\n",
        "        return t.half()\n",
        "    return t\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_resnet_batch_top1(pil_imgs):\n",
        "    \"\"\"\n",
        "    pil_imgs: [PIL.Image, ...]\n",
        "    return: [[{\"idx\": int, \"prob\": float}], ...]  (각 이미지당 Top-1만)\n",
        "    \"\"\"\n",
        "    if not pil_imgs:\n",
        "        return []\n",
        "    xs = [preprocess_pil(im) for im in pil_imgs]\n",
        "    x = torch.stack(xs).to(DEVICE)\n",
        "\n",
        "    if DEVICE.type == 'cuda':\n",
        "        logits = RESNET_MODEL(x)\n",
        "    else:\n",
        "        logits = RESNET_MODEL(x)\n",
        "\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "    top1_prob, top1_idx = torch.topk(probs, 1, dim=1)\n",
        "\n",
        "    all_results = []\n",
        "    for i in range(probs.shape[0]):\n",
        "        res_i = [{\n",
        "            \"idx\": int(top1_idx[i, 0].item()),\n",
        "            \"prob\": float(top1_prob[i, 0].item()),\n",
        "        }]\n",
        "        all_results.append(res_i)\n",
        "    return all_results\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 3) YOLO 감지 + 크롭 생성 (단일 모드용)\n",
        "# -------------------------------------------------\n",
        "YOLO_DEVICE = 0 if DEVICE.type == \"cuda\" else \"cpu\"\n",
        "YOLO_MODEL = YOLO(BEST_YOLO)\n",
        "\n",
        "def detect_yolo_boxes(img_path):\n",
        "    det = YOLO_MODEL(\n",
        "        img_path,\n",
        "        imgsz=YOLO_IMGSZ,\n",
        "        conf=YOLO_CONF,\n",
        "        iou=YOLO_IOU,\n",
        "        device=YOLO_DEVICE,\n",
        "        verbose=False\n",
        "    )[0]\n",
        "\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    W, H = img.size\n",
        "\n",
        "    boxes = []\n",
        "    if det.boxes is not None and len(det.boxes) > 0:\n",
        "        for b in det.boxes.xyxy.cpu().numpy().tolist():\n",
        "            x1, y1, x2, y2 = map(int, b)\n",
        "            x1 = max(0, x1)\n",
        "            y1 = max(0, y1)\n",
        "            x2 = min(W-1, x2)\n",
        "            y2 = min(H-1, y2)\n",
        "            if (x2-x1) >= MIN_BOX_SIDE_PX and (y2-y1) >= MIN_BOX_SIDE_PX:\n",
        "                boxes.append([x1, y1, x2, y2])\n",
        "\n",
        "    return img, boxes\n",
        "\n",
        "def square_crop_from_bbox(pil_img, xyxy, scale=1.3):\n",
        "    W, H = pil_img.size\n",
        "    x1, y1, x2, y2 = xyxy\n",
        "    cx = (x1 + x2) / 2.0\n",
        "    cy = (y1 + y2) / 2.0\n",
        "    bw = x2 - x1\n",
        "    bh = y2 - y1\n",
        "    side = max(bw, bh) * scale\n",
        "    side = max(side, MIN_BOX_SIDE_PX * 1.5)\n",
        "\n",
        "    half = side / 2.0\n",
        "    nx1 = int(round(cx - half))\n",
        "    ny1 = int(round(cy - half))\n",
        "    nx2 = int(round(cx + half))\n",
        "    ny2 = int(round(cy + half))\n",
        "\n",
        "    nx1 = max(0, nx1)\n",
        "    ny1 = max(0, ny1)\n",
        "    nx2 = min(W, nx2)\n",
        "    ny2 = min(H, ny2)\n",
        "    if nx2 <= nx1 or ny2 <= ny1:\n",
        "        return None\n",
        "\n",
        "    return pil_img.crop((nx1, ny1, nx2, ny2))\n",
        "\n",
        "def make_crops_for_single_mode(img_path):\n",
        "    img, boxes = detect_yolo_boxes(img_path)\n",
        "    W, H = img.size\n",
        "    img_area = W * H\n",
        "\n",
        "    use_full_image_only = False\n",
        "    if len(boxes) == 1:\n",
        "        x1, y1, x2, y2 = boxes[0]\n",
        "        box_area = (x2-x1) * (y2-y1)\n",
        "        area_ratio = box_area / float(img_area + 1e-9)\n",
        "        if area_ratio >= FULL_IMAGE_AREA_RATIO_THRESHOLD:\n",
        "            use_full_image_only = True\n",
        "\n",
        "    crop_images = []\n",
        "    if use_full_image_only:\n",
        "        crop_images.append(img.copy())\n",
        "    else:\n",
        "        for bbox in boxes:\n",
        "            sq = square_crop_from_bbox(img, bbox, scale=SQUARE_SCALE)\n",
        "            if sq is None:\n",
        "                continue\n",
        "            crop_images.append(sq)\n",
        "\n",
        "    if not crop_images:\n",
        "        crop_images.append(img.copy())\n",
        "\n",
        "    return crop_images\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 4) 엔드투엔드 단일 알약 Top-1 추론\n",
        "# -------------------------------------------------\n",
        "def infer_pill_image_single_top1(img_path: str):\n",
        "    \"\"\"\n",
        "    이미지 전체 기준 최종 Top-1만 리턴.\n",
        "    return:\n",
        "      {\"idx\": <class_idx>, \"dl_idx\": \"<dl_idx>\", \"prob\": <float>}\n",
        "    \"\"\"\n",
        "    crops = make_crops_for_single_mode(img_path)\n",
        "    batch_results = predict_resnet_batch_top1(crops)\n",
        "\n",
        "    # 클래스별 max-pooling (Top-1 결과만 모아도 동일 로직)\n",
        "    agg_scores = {}\n",
        "    for crop_res in batch_results:\n",
        "        t = crop_res[0]\n",
        "        idx = t[\"idx\"]\n",
        "        p   = t[\"prob\"]\n",
        "        if idx not in agg_scores or p > agg_scores[idx]:\n",
        "            agg_scores[idx] = p\n",
        "\n",
        "    if not agg_scores:\n",
        "        return None\n",
        "\n",
        "    best_idx, best_prob = max(agg_scores.items(), key=lambda x: x[1])\n",
        "    dl_idx = idx_to_dl_idx(best_idx)\n",
        "\n",
        "    return {\n",
        "        \"idx\":   best_idx,\n",
        "        \"dl_idx\": dl_idx,\n",
        "        \"prob\":  best_prob,\n",
        "    }\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 5) 테스트 실행\n",
        "# -------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    assert os.path.exists(IMG_PATH), f\"이미지 없음: {IMG_PATH}\"\n",
        "    res = infer_pill_image_single_top1(IMG_PATH)\n",
        "    print(\"=== SINGLE MODE TOP-1 RESULT ===\")\n",
        "    if res is None:\n",
        "        print(\"No prediction.\")\n",
        "    else:\n",
        "        print(f\"class_idx={res['idx']}, dl_idx={res['dl_idx']}, prob={res['prob']*100:.2f}%\")\n",
        "    # 다른 API에 넘길 때는 res 그대로 사용하면 됨\n"
      ]
    }
  ]
}